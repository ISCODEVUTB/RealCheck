{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a215d07",
   "metadata": {},
   "source": [
    "# Clasificador de texto para el verificador de noticias (RealCheck)\n",
    "\n",
    "En este proyecto, se implementará un clasificador de texto utilizando técnicas de aprendizaje automático con el objetivo de verificar si la frase u oración proporcionada puede corresponder a una noticia verificable o por el contrario, se trata de un comentario o pregunta que no tiene una base factual clara. \n",
    "\n",
    "El modelo entrenado será utilizado en la producción para predecir la verificabilidad de las noticias. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a78283a",
   "metadata": {},
   "source": [
    "## Instalación de los paquetes necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c94117",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install torch\n",
    "!pip3 install spacy\n",
    "!python3 -m spacy download es_dep_news_trf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1594ccf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "/usr/lib/python3/dist-packages/secretstorage/dhcrypto.py:15: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/usr/lib/python3/dist-packages/secretstorage/util.py:19: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.2.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.8 MB 1.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting joblib>=1.1.1\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "\u001b[K     |████████████████████████████████| 297 kB 1.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: scipy>=1.3.2 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.17.3 in /usr/lib/python3/dist-packages (from scikit-learn) (1.17.4)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (2.0.0)\n",
      "Installing collected packages: joblib, scikit-learn\n",
      "Successfully installed joblib-1.2.0 scikit-learn-1.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip3 install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8decac",
   "metadata": {},
   "source": [
    "## Importación de los módulos a usar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b123f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84c2090",
   "metadata": {},
   "source": [
    "## Cargar los datos del archivo CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db7245b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  texto  noticia\n",
      "0     No puedo creer que haya personas que sigan jus...        0\n",
      "1           Hoy hace un día precioso para ir a la playa        0\n",
      "2     Encuentran en San Andrés a migrantes que iban ...        1\n",
      "3     Polémica por tarifas diferenciales a extranjer...        1\n",
      "4     Se canceló el partido de fútbol de este fin de...        0\n",
      "...                                                 ...      ...\n",
      "1995  Nevado del Ruiz: ¿cuáles son los planes de con...        1\n",
      "1996  Hoy voy a hacer una llamada telefónica a un am...        0\n",
      "1997  Por ahora, Colombia no firmará nuevos contrato...        1\n",
      "1998  Hipopótamo causa otro accidente en Puerto Triu...        1\n",
      "1999  Me parece increíble que haya personas que toda...        0\n",
      "\n",
      "[2000 rows x 2 columns]\n",
      "1    1000\n",
      "0    1000\n",
      "Name: noticia, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Dataset.csv', header=None, names=['texto', 'noticia'])\n",
    "print(df)\n",
    "\n",
    "print(df[\"noticia\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d7e3d0",
   "metadata": {},
   "source": [
    "## Preprocesar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d109a0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"es_dep_news_trf\")\n",
    "\n",
    "def Tokenizar(text):\n",
    "    tokens = [token.lemma_.lower() for token in nlp(text) if not token.is_stop and not token.is_punct]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3072ca92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['creer', 'persona', 'seguir', 'justificar', 'discriminación', 'racismo', 'pleno', 'siglo', 'xxi']\n",
      "['abuela', 'galleta', 'avena', 'visitar']\n"
     ]
    }
   ],
   "source": [
    "# Mostrar ejemplo de preprocesamiento\n",
    "print(Tokenizar(df['texto'][0]))\n",
    "print(Tokenizar(df['texto'][5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff690db0",
   "metadata": {},
   "source": [
    "## Separar los datos en conjuntos de entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "361577d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad datos entrenamiento:  1600\n",
      "Cantidad datos prueba:  400\n"
     ]
    }
   ],
   "source": [
    "X = df['texto']\n",
    "y = df['noticia']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=df[\"noticia\"])\n",
    "\n",
    "print(\"Cantidad datos entrenamiento: \",len(X_train))\n",
    "print(\"Cantidad datos prueba: \",len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434535b5",
   "metadata": {},
   "source": [
    "## Vectorizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c08c2659",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_vectorizer = CountVectorizer(tokenizer = Tokenizar, binary=True,  token_pattern=None)\n",
    "train_X = real_vectorizer.fit_transform(X_train)\n",
    "test_X = real_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12ff4693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.92\n",
      "Precision: 0.9666666666666667\n",
      "Recall: 0.87\n",
      "Specificity: 0.97\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(C=1, penalty='l2', solver='liblinear')\n",
    "clf.fit(train_X, y_train)\n",
    "\n",
    "# Hacer predicciones con los datos de prueba\n",
    "y_pred = clf.predict(test_X)\n",
    "\n",
    "# Calcular la precisión del modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calcular la precisión del modelo\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# Calcular la sensibilidad del modelo\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# Calcular la especificidad del modelo\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "print(\"Specificity:\", specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ae3e2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - Al perro le gusta comer carne en el centro de manhatan: Probabilidad: 0.97\n",
      "1 - Nuevo informe muestra el aumento de la violencia de género en la región.: Probabilidad: 0.68\n",
      "1 - Empresa anuncia el lanzamiento de un nuevo producto revolucionario en el mercado.: Probabilidad: 0.91\n",
      "0 - La pizza no me gusta: Probabilidad: 0.89\n",
      "0 - Manuela le gusta cepillarse todo los dias en el congreso: Probabilidad: 0.85\n",
      "1 - La marihuana queda totalmente prohibida en toda Colombia: Probabilidad: 0.94\n"
     ]
    }
   ],
   "source": [
    "frases = [\n",
    "  'Al perro le gusta comer carne en el centro de manhatan',\n",
    "  'Nuevo informe muestra el aumento de la violencia de género en la región.',\n",
    "  'Empresa anuncia el lanzamiento de un nuevo producto revolucionario en el mercado.',\n",
    "  'La pizza no me gusta',\n",
    "  'Manuela le gusta cepillarse todo los dias en el congreso',\n",
    "  'La marihuana queda totalmente prohibida en toda Colombia'\n",
    "]\n",
    "\n",
    "frases_X = real_vectorizer.transform(frases)\n",
    "predicciones = clf.predict(frases_X)\n",
    "probabilidades = clf.predict_proba(frases_X)\n",
    "\n",
    "\n",
    "for text, label, p in zip(frases, predicciones, probabilidades):\n",
    "    if label == 0:\n",
    "        print(f\"{label} - {text}: Probabilidad: {round(p[0],2)}\")\n",
    "    else:\n",
    "        print(f\"{label} - {text}: Probabilidad: {round(p[1],2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "064e8e6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clf.joblib']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Exportar el vectorizador\n",
    "joblib.dump(real_vectorizer, 'real_vectorizer.joblib')\n",
    "\n",
    "# Exportar el modelo\n",
    "joblib.dump(clf, 'clf.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adb8f3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
